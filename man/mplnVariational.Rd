% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mplnMCMCEMClustering.R
\name{mplnVariational}
\alias{mplnVariational}
\title{Clustering Using MPLN Via Variational-EM}
\usage{
mplnVariational(
  dataset,
  membership = "none",
  gmin,
  gmax,
  initMethod = "kmeans",
  nInitIterations = 2,
  normalize = "Yes"
)
}
\arguments{
\item{dataset}{A dataset of class matrix and type integer such that
rows correspond to observations and columns correspond to variables.
The dataset have dimensions n x d, where n is the total number of
observations and d is the dimensionality. If rowSums are zero, these
rows will be removed prior to cluster analysis.}

\item{membership}{A numeric vector of length nrow(dataset) containing the
cluster membership of each observation. If not available,
leave as "none".}

\item{gmin}{A positive integer specifying the minimum number of components
to be considered in the clustering run.}

\item{gmax}{A positive integer, >= gmin, specifying the maximum number of
components to be considered in the clustering run.}

\item{initMethod}{An algorithm for initialization. Current options are
"kmeans", "random", "medoids", "clara", or "fanny". Default is "kmeans".}

\item{nInitIterations}{A positive integer or zero, specifying the number
of initialization runs to be performed. This many runs, each with 10
iterations, will be performed via MPLNClust and values from the run with
highest log-likelihood will be used as initialization values. Default is 2.}

\item{normalize}{A string with options "Yes" or "No" specifying
if normalization should be performed. Currently, normalization factors
are calculated using TMM method of edgeR package. Default is "Yes".}
}
\value{
Returns an S3 object of class mplnVariational with results.
\itemize{
\item dataset - The input dataset on which clustering is performed.
\item dimensionality - Dimensionality of the input dataset.
\item normalizationFactors - A vector of normalization factors used
for input dataset.
\item gmin - Minimum number of components/clusters considered in the clustering
run.
\item gmax - Maximum number of components/clusters considered in the clustering
run.
\item initalizationMethod - Method used for initialization.
\item allResults - A list with all results.
\item logLikelihood - A vector with value of final log-likelihoods for
each component/cluster size.
\item numbParameters - A vector with number of parameters for each
component/cluster size.
\item trueLabels - The vector of true labels, if provided by user.
\item ICLresults - A list with all ICL model selection results.
\item BICresults - A list with all BIC model selection results.
\item AICresults - A list with all AIC model selection results.
\item AIC3results - A list with all AIC3 model selection results.
\item slopeHeuristics - If more than 10 models are considered, slope heuristic
results as obtained via capushe::capushe().
\item DjumpModelSelected - If more than 10 models are considered, slope heuristic
results as obtained via capushe::capushe().
\item DDSEModelSelected - If more than 10 models are considered, slope heuristic
results as obtained via capushe::capushe().
\item totalTime - Total time used for clustering and model selection.
}
}
\description{
Performs clustering using mixtures of multivariate Poisson-log
normal (MPLN) distribution with variational expectation-maximization
(EM) for parameter estimation. Model selection is performed using
AIC, AIC3, BIC and ICL. If more than 10 models are considered, Djump
and DDSE is also applied for model selection. No internal
parallelization, thus code is run in serial.
}
\examples{
# Example 1
trueMu1 <- c(6.5, 6, 6, 6, 6, 6)
trueMu2 <- c(2, 2.5, 2, 2, 2, 2)

trueSigma1 <- diag(6) * 2
trueSigma2 <- diag(6)

# Generating simulated data
sampleData <- MPLNClust::mplnDataGenerator(nObservations = 1000,
                     dimensionality = 6,
                     mixingProportions = c(0.79, 0.21),
                     mu = rbind(trueMu1, trueMu2),
                     sigma = rbind(trueSigma1, trueSigma2),
                     produceImage = "No")

# Clustering
mplnResults <- MPLNClust::mplnVariational(
                     dataset = sampleData$dataset,
                     membership = sampleData$trueMembership,
                     gmin = 1,
                     gmax = 2,
                     initMethod = "kmeans",
                     nInitIterations = 2,
                     normalize = "Yes")
names(mplnResults)

# Example 2
# Use an external dataset
if (requireNamespace("MBCluster.Seq", quietly = TRUE)) {
library(MBCluster.Seq)
data("Count")
dim(Count)

# Clustering subset of data
mplnResultsMBClust <- MPLNClust::mplnVariational(
                            dataset = as.matrix(Count[c(1:100), ]),
                            membership = "none",
                            gmin = 1,
                            gmax = 5,
                            initMethod = "kmeans",
                            nInitIterations = 2,
                            normalize = "Yes")
names(mplnResultsMBClust)

}

}
\references{
Aitchison, J. and C. H. Ho (1989). The multivariate Poisson-log normal distribution.
\emph{Biometrika} 76.

Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In \emph{Second International Symposium on Information Theory}, New York, NY,
USA, pp. 267–281. Springer Verlag.

Arlot, S., Brault, V., Baudry, J., Maugis, C., and Michel, B. (2016).
capushe: CAlibrating Penalities Using Slope HEuristics. R package version 1.1.1.

Biernacki, C., G. Celeux, and G. Govaert (2000). Assessing a mixture model for
clustering with the integrated classification likelihood. \emph{IEEE Transactions
on Pattern Analysis and Machine Intelligence} 22.

Bozdogan, H. (1994). Mixture-model cluster analysis using model selection criteria
and a new informational measure of complexity. In \emph{Proceedings of the First US/Japan
Conference on the Frontiers of Statistical Modeling: An Informational Approach:
Volume 2 Multivariate Statistical Modeling}, pp. 69–113. Dordrecht: Springer Netherlands.

Robinson, M.D., and Oshlack, A. (2010). A scaling normalization method for differential
expression analysis of RNA-seq data. \emph{Genome Biology} 11, R25.

Schwarz, G. (1978). Estimating the dimension of a model. \emph{The Annals of Statistics}
6.

Silva, A. et al. (2019). A multivariate Poisson-log normal mixture model
for clustering transcriptome sequencing data. \emph{BMC Bioinformatics} 20.
\href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2916-0}{Link}

Subedi, S., and R. Browne (2020). A parsimonious family of multivariate Poisson-lognormal
distributions for clustering multivariate count data. arXiv preprint arXiv:2004.06857.
\href{https://arxiv.org/pdf/2004.06857.pdf}{Link}
}
\author{
{Anjali Silva, \email{anjali.silva@uhnresearch.ca}, Sanjeena Dang,
\email{sdang@math.binghamton.edu}. }
}
