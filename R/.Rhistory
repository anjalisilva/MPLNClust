if (!require(parallel)) install.packages("parallel")
?parallel
#### functions ####
# z value calculation function
zvalue_calculation<-function(theta_Stan,dataset,G,mu_g,Sig_g,PI, normalizefactors){
d<-ncol(dataset)
n<-nrow(dataset)
forz=sapply(c(1:G), function(g) sapply(c(1:n), function(i) PI[g]*exp(t(dataset[i,])%*%(theta_Stan[[g]][i,]+normalizefactors)-sum(exp(theta_Stan[[g]][i,]+normalizefactors))-sum(lfactorial(dataset[i,]))-
d/2*log(2*pi)-1/2*log(det(Sig_g[((g-1)*d+1):(g*d),]))-0.5*t(theta_Stan[[g]][i,]-mu_g[g,])%*%solve(Sig_g[((g-1)*d+1):(g*d),])%*%(theta_Stan[[g]][i,]-mu_g[g,])) ) )
if (G==1){
errorpossible<-Reduce(intersect, list(which(forz==0),which(rowSums(forz)==0)))
zvalue<-forz/rowSums(forz)
zvalue[errorpossible,]<-1
}else {zvalue<-forz/rowSums(forz)}
return(zvalue)
}
# likelihood calculation function
calc_likelihood<-function(z, PI, dataset, mu_g, G, Sig_g, theta_Stan, normalizefactors){
n<-nrow(dataset)
like<-matrix(NA, nrow=n, ncol=G)
d<-ncol(dataset)
like=sapply(c(1:G), function(g) sapply(c(1:n), function(i) z[i,g] *(log(PI[g]) +
t(dataset[i,])%*%(theta_Stan[[g]][i,]+normalizefactors)-sum(exp(theta_Stan[[g]][i,]+normalizefactors))-sum(lfactorial(dataset[i,]))-
d/2*log(2*pi)-1/2*log(det(Sig_g[((g-1)*d+1):(g*d),]))-0.5*t(theta_Stan[[g]][i,]-mu_g[g,])%*%solve(Sig_g[((g-1)*d+1):(g*d),])%*%(theta_Stan[[g]][i,]-mu_g[g,])) ) )
loglike<-sum(rowSums(like))
return(loglike)
}
# stan sampling function
stanrun<-function(model, gmin, gmax, dataset, mu_all_outer, it_outer, sigma_all_outer, n_iterations, n_chains=n_chains, normalizefacs){
fitrstan<-list()
d<-ncol(dataset)
for (g in gmin:gmax){
data1=list(d=ncol(dataset),N=nrow(dataset),y=dataset,mu=mu_all_outer[[it_outer-1]][g,],Sigma=sigma_all_outer[[it_outer-1]][((g-1)*d+1):(g*d),], normfactors=as.vector(normalizefacs))
stanproceed<-0
try=1
while (!stanproceed){
cat("\nRstan generating sample at outer iteration", it_outer, "for g: ", g)
cat("\nNumber of iterations is", n_iterations, "\n")
fitrstan[[g]]<-sampling(object=model,
data=data1,
iter=n_iterations, chains = n_chains, verbose=FALSE, refresh=-1)
if (all(summary(fitrstan[[g]])$summary[,"Rhat"] < 1.1) == TRUE && all(summary(fitrstan[[g]])$summary[,"n_eff"]>100) == TRUE){
stanproceed<-1
} else if(all(summary(fitrstan[[g]])$summary[,"Rhat"] < 1.1) != TRUE || all(summary(fitrstan[[g]])$summary[,"n_eff"]>100) != TRUE){
if(try == 10){ # stop after 10 tries
stanproceed = 1
}
n_iterations = n_iterations+100
try=try+1
}
}
} # close g loop
results <- list(fitrstan = fitrstan,
n_iterations = n_iterations)
class(results) <- "RStan"
return(results)
return(results)
}
# initialization function
initializationrun<-function(gmodel, dataset, init_method, n_init_iterations, n_chains, n_iterations, initialization=NA, normalizefactors, mod){
z<-init_runs<-list()
logL_init<-vector()
n<-nrow(dataset)
d<-ncol(dataset)
for(iterations in 1:n_init_iterations){
if (init_method=="kmeans" | is.na(init_method)){
if (!require(mclust)) suppressWarnings(install.packages('mclust')) # loading needed packages
suppressWarnings(library(mclust))
z[[iterations]]<-unmap(kmeans(log(dataset+1/3),gmodel)$cluster)
}else if (init_method=="random"){
if(gmodel==1){ # generating z if g=1
z[[iterations]] <- as.matrix(rep.int(1, times=n), ncol=gmodel, nrow=n)
} else { # generating z if g>1
z_conv=0
while(!z_conv){ # ensure that dimension of z is same as G (i.e.
# if one column contains all 0s, then generate z again)
z[[iterations]] <- t(rmultinom(n, size = 1, prob=rep(1/gmodel,gmodel)))
if(length(which(colSums(z[[iterations]])>0)) ==gmodel){
z_conv=1
}
}
}
}else if (init_method=="medoids"){
if (!require(cluster)) install.packages('cluster')
library(cluster)
if (!require(mclust)) suppressWarnings(install.packages('mclust')) # loading needed packages
suppressWarnings(library(mclust))
z[[iterations]]<-unmap(pam(log(dataset+1/3),k=gmodel)$cluster)
}else if (init_method=="clara"){
if (!require(cluster)) install.packages('cluster')
library(cluster)
z[[iterations]]<-unmap(clara(log(dataset+1/3),k=gmodel)$cluster)
}else if (init_method=="fanny"){
if (!require(cluster)) install.packages('cluster')
library(cluster)
z[[iterations]]<-unmap(fanny(log(dataset+1/3),k=gmodel)$cluster)
}
init_runs[[iterations]]=cluster_mpln(dataset=dataset,z=z[[iterations]],G=gmodel,n_chains=n_chains,n_iterations=n_iterations, initialization="init", normalizefac=normalizefactors, mod=mod)
logL_init[iterations] <- unlist(tail((init_runs[[iterations]]$loglikelihood), n=1))
}
initialization<-init_runs[[which(logL_init==max(logL_init, na.rm = TRUE))[1]]]
return(initialization)
}
# BIC function
BIC_function = function(ll, k, n, run, gmin, gmax, dataset){
BIC <- -2*ll+ (k* log(n))
BICmodel<-seq(gmin, gmax, 1)[grep(min(BIC,na.rm = TRUE), BIC)]
BICmodel_labels<-run[[grep(min(BIC,na.rm = TRUE), BIC)]]$allresults$clusterlabels
BICMessage<-NA
if (max(BICmodel_labels)!=BICmodel){
BICmodel<-max(BICmodel_labels)
BICMessage<-"Spurious or empty cluster resulted."
}
BICresults<-list(allBICvalues=BIC,
BICmodelselected=BICmodel,
BICmodelselected_labels=BICmodel_labels,
BICMessage=BICMessage)
class(BICresults) <- "BIC"
return(BICresults)
}
# ICL function
ICL_function = function(bIc, gmax, gmin, run, dataset){
ICL<-vector()
for (g in 1:(gmax-gmin+1)){
z<-run[[g]]$allresults$probaPost
mapz<-mclust::unmap(run[[g]]$allresults$clusterlabels)
forICL<-function(g){sum(log(z[which(mapz[,g]==1),g]))}
ICL[g] <- bIc$allBICvalues[g] + sum(sapply(1:ncol(mapz),forICL))
}
ICLmodel<-seq(gmin, gmax, 1)[grep(min(ICL, na.rm = TRUE), ICL)]
ICLmodel_labels<-run[[grep(min(ICL, na.rm = TRUE), ICL)]]$allresults$clusterlabels
ICLMessage<-NA
if (max(ICLmodel_labels)!=ICLmodel){
ICLmodel<-max(ICLmodel_labels)
ICLMessage<-"Spurious or empty cluster resulted."
}
ICLresults<-list(allICLvalues=ICL,
ICLmodelselected=ICLmodel,
ICLmodelselected_labels=ICLmodel_labels,
ICLMessage=ICLMessage)
class(ICLresults) <- "ICL"
return(ICLresults)
}
# AIC function
AIC_function = function(ll, k, run, gmin, gmax, dataset){
AIC <- -2*ll+ 2*k
AICmodel<-seq(gmin, gmax, 1)[grep(min(AIC,na.rm = TRUE), AIC)]
AICmodel_labels<-run[[grep(min(AIC,na.rm = TRUE), AIC)]]$allresults$clusterlabels
AICMessage<-NA
if (max(AICmodel_labels)!=AICmodel){
AICmodel<-max(AICmodel_labels)
AICMessage<-"Spurious or empty cluster resulted."
}
AICresults<-list(allAICvalues=AIC,
AICmodelselected=AICmodel,
AICmodelselected_labels=AICmodel_labels,
AICMessage=AICMessage)
class(AICresults) <- "AIC"
return(AICresults)
}
# AIC3 function
AIC3_function = function(ll, k, run, gmin, gmax, dataset){
AIC3 <- -2*ll+ 3*k
AIC3model<-seq(gmin, gmax, 1)[grep(min(AIC3,na.rm = TRUE), AIC3)]
AIC3model_labels<-run[[grep(min(AIC3,na.rm = TRUE), AIC3)]]$allresults$clusterlabels
AIC3Message<-NA
if (max(AIC3model_labels)!=AIC3model){
AIC3model<-max(AIC3model_labels)
AIC3Message<-"Spurious or empty cluster resulted."
}
AIC3results<-list(allAIC3values=AIC3,
AIC3modelselected=AIC3model,
AIC3modelselected_labels=AIC3model_labels,
AIC3Message=AIC3Message)
class(AIC3results) <- "AIC3"
return(AIC3results)
}
# parameter calculation
calculate_parameters<-function(g,dataset){
d<-ncol(dataset)
mu_para<-d*g
sigma_para<-(d*((d+1)/2))*g
pi_para<-g-1 # because if you have g-1 parameters, you can do 1-these to get the last one
paratotal<-mu_para+sigma_para+pi_para # total parameters are
return(paratotal)
}
# clustering function
cluster_mpln<-function(dataset,z,G,n_chains,n_iterations, initialization, normalizefac, mod){
d<-ncol(dataset)
n<-nrow(dataset)
norm_mu_outer<-norm_sigma_outer<-vector() # for convergence calculation
median_mu_outer<-median_sigma_outer<-list()
mu_all_outer<-sigma_all_outer<-list() # for saving mu and sigma values
obs<-PI<-logL<-vector()
it_outer<-2 # the starting value of interation for outer loop
conv_outer<-0
if (all(is.na(initialization))==TRUE || all(initialization =="init")){
mu_all_outer[[1]]<-mu_g <- matrix(log(mean(dataset)), ncol=d, nrow=G) # mean for both t and normal distribution
sigma_all_outer[[1]]<-Sig_g <- do.call("rbind", rep(list(cov(log(dataset+1))*d), G)) # sig for sigma of t distribtuion
}else{
mu_all_outer[[1]]<-mu_g <- initialization$finalmu
sigma_all_outer[[1]]<-Sig_g <- initialization$finalsigma
z=initialization$probaPost
}
while(!conv_outer){
cat("************** Running for G =",G,"and Iteration =",it_outer,"******************")
obs=apply(z, 2, sum) # number of observations in each group
PI=sapply(obs, function(x) x/n)  # obtain probability of each group
theta_Stan<-E_theta2<-list()
rstan_results<-stanrun(model=mod, gmin=1,gmax=G,dataset=dataset,mu_all_outer=mu_all_outer, it_outer=it_outer, sigma_all_outer=sigma_all_outer, n_iterations=n_iterations, n_chains=n_chains, normalizefacs=normalizefac)
# turn results into a matrix
tt=lapply(as.list(c(1:G)), function(x) as.matrix(rstan_results$fitrstan[[x]]) )
for (g in 1:G){
# expected value of theta
theta_Stan[[g]]=t(sapply(c(1:n), function(i) colMeans(tt[[g]][,c(i,(t(sapply(c(1:n), function(x) c(1:(d-1))*n+x)))[i,])]) ))
# expected value of theta theta-transform
E_theta2[[g]]=lapply(as.list(c(1:n)), function(i) z[i,g]*t(tt[[g]][,c(i,(t(sapply(c(1:n), function(x) c(1:(d-1))*n+x)))[i,])])%*%tt[[g]][,c(i,(t(sapply(c(1:n), function(x) c(1:(d-1))*n+x)))[i,])]/((0.5*rstan_results$n_iterations)*n_chains))
}
# updating value of mu
mu_all_outer[[it_outer]]= mu_g=t(sapply(c(1:G), function(g) colSums(z[,g]*theta_Stan[[g]])/sum(z[,g])))
# updating value of sigma
sigma_all_outer[[it_outer]]=Sig_g=do.call(rbind, lapply(as.list(c(1:G)), function(g) Reduce("+",E_theta2[[g]])/sum(z[,g])-mu_g[g,]%*%t(mu_g[g,])))
# updating log-likelihood
logL[it_outer]<-calc_likelihood(z=z, PI=PI, dataset=dataset, mu_g=mu_all_outer[[it_outer]], G=G, Sig_g=sigma_all_outer[[it_outer]], theta_Stan=theta_Stan, normalizefactors=normalizefac)
# convergence of outer loop
threshold_outer<-10
if(it_outer>(threshold_outer)){
if (all(heidel.diag(logL[-1], eps=0.1, pvalue=0.05)[,c(1,4)]==1) || it_outer>100){
programclust<-vector()
programclust<-map(z)
# checking for empty clusters
J <- 1:ncol(z)
K <- as.logical(match(J, sort(unique(programclust)), nomatch = 0))
if(length(J[!K])>0){ # J[!K] tells which are empty clusters
z<-z[,-J[!K]]
programclust<-map(z)
}
conv_outer<-1
}
}
# if running for initialization, need to stop after 1 iteration
if(it_outer==2 && all(is.na(initialization) !=TRUE)){
if(all(initialization == "init")){
programclust<-vector()
programclust<-map(z)
conv_outer<-1
}
}
# only update until convergence, not after
if(conv_outer!=1){
z<-zvalue_calculation(theta_Stan=theta_Stan,dataset=dataset,G=G,mu_g=mu_g,Sig_g=Sig_g,PI=PI, normalizefactors=normalizefac)
it_outer<-it_outer+1 # updating outer loop iteration
n_iterations = n_iterations+10
}
} # end of outer loop
results <- list(finalmu=mu_all_outer[[it_outer]]+ matrix(rep(normalizefac,nrow(mu_all_outer[[it_outer]])),byrow=TRUE,ncol=ncol(mu_all_outer[[it_outer]])),
finalsigma=sigma_all_outer[[it_outer]],
allmu = lapply(mu_all_outer, function(x) (x+matrix(rep(normalizefac,nrow(mu_all_outer[[it_outer]])),byrow=TRUE,ncol=ncol(mu_all_outer[[it_outer]])))),
allsigma = sigma_all_outer,
clusterlabels = programclust,
iterations = it_outer,
proportion = PI,
loglikelihood = logL,
probaPost = z)
class(results) <- "MPLNcluster"
return(results)
}
# calling the clustering function
calling_clustering = function(dataset, Gmin, Gmax, n_chains, n_iterations=NA, init_method=NA, n_init_iterations=NA, norm_factors, mod){
ptm_inner = proc.time()
for (gmodel in 1:(Gmax-Gmin+1)){
if(length(1:(Gmax-Gmin+1)) == Gmax){
clustersize = gmodel
}else if(length(1:(Gmax-Gmin+1)) < Gmax){
clustersize = seq(Gmin, Gmax, 1)[gmodel]
}
if(n_init_iterations!=0){
initializeruns=initializationrun(gmodel=clustersize, dataset=dataset, init_method=init_method, n_init_iterations=n_init_iterations, n_chains=n_chains, n_iterations=n_iterations, initialization=NA, normalizefactors=norm_factors, mod=mod)
allruns=cluster_mpln(dataset=dataset,z=NA,G=clustersize,n_chains=n_chains,n_iterations=n_iterations, initialization=initializeruns, normalizefac=norm_factors, mod=mod)
}else if(n_init_iterations == 0){
allruns=cluster_mpln(dataset=dataset, z=unmap(kmeans(log(dataset+1/3),clustersize)$cluster), G=clustersize, n_chains=n_chains, n_iterations=n_iterations, initialization=NA, normalizefac=norm_factors, mod=mod)
}
}
final_inner<-proc.time()-ptm_inner
RESULTS <- list(  gmin = Gmin,
gmax = Gmax,
initalization_method = init_method,
allresults = allruns,
totaltime = final_inner)
class(RESULTS) <- "MPLN"
return(RESULTS)
}
# main function
MPLNClustering<-function(dataset, membership=NA, Gmin, Gmax, n_chains=3, n_iterations=NA, init_method="kmeans", n_init_iterations=5, normalize="TMM"){
ptm<-proc.time()
# doing checks
if (typeof(dataset) != "double" & typeof(dataset) != "integer"){
stop("Dataset type needs to be integer");}
if (Gmax<Gmin){
stop("Gmax cannot be less than Gmin");}
if(is.na(n_iterations)) n_iterations <- 1000
if(is.na(n_chains) || n_chains<3) {
n_chains <- 3
print("Recommended number of chains is minimum 3. 'n_chains' set to 3")}
if(n_iterations<40){
stop("RStan n_iterations argument should be greater than 40");}
if((is.na(n_init_iterations) != TRUE && n_init_iterations == !0) && is.na(init_method) == TRUE){
stop("Number of initialization iterations specified, but no initialization method selected");}
d<-ncol(dataset)
n<-nrow(dataset)
if(all(is.na(membership)!=TRUE) && length(membership)!=n){
stop("Length of membership character vector and sample size of dataset should match");}
if(all(is.na(membership)!=TRUE) && all((diff(sort(unique(membership)))==1)!=TRUE) ){
stop("Cluster memberships in the membership vector are missing a cluster, e.g. 1,3,4,5,6 is missing cluster 2");}
if(length(which(apply(dataset, 1, function(x) all(x==0))==TRUE))!=0){
cat("\nDataset row(s)", c(which(apply(dataset, 1, function(x) all(x==0))==TRUE)), "will be removed as this/these contain(s) all zeros")
if(all(is.na(membership)==FALSE)){membership<-membership[-c(which(apply(dataset, 1, function(x) all(x==0))==TRUE))]}
dataset<-dataset[-c(which(apply(dataset, 1, function(x) all(x==0))==TRUE)),]
n<-nrow(dataset)
}
if(all(is.na(membership)==TRUE)){
membership<-"Not provided"}
if (Gmax > n){
stop("Gmax cannot be larger than n");}
# loading needed packages
if (!require(mvtnorm)) install.packages("mvtnorm")
if (!require(mclust)) install.packages("mclust")
if (!require(mclust)) install.packages("coda")
if (!require(mclust)) install.packages("capushe")
if (!require(edgeR)) install.packages("edgeR")
if (!require(clusterGeneration)) install.packages("clusterGeneration")
if (!require(pheatmap)) install.packages("pheatmap")
if (!require(RColorBrewer)) install.packages("RColorBrewer")
if (!require(gplots)) install.packages("gplots")
# Making RStan model
if (!require(rstan)) {
install.packages('rstan')
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()) }
if (!require(Rcpp)) install.packages('Rcpp')
mod <<- stan_model("MPLN.stan")
if (!require(parallel)) install.packages("parallel")
# Running code in parallel
# Calculate the number of cores
no_cores = detectCores()
# Initiate cluster
cl = makeCluster(no_cores-1)
# Doing clusterExport
clusterExport(cl,c("mod", "testing_dataset","zvalue_calculation", "calc_likelihood", "stanrun", "initializationrun", "BIC_function","ICL_function","AIC_function","AIC3_function", "calculate_parameters", "cluster_mpln", "calling_clustering"))
# Packages need to be downloaded using clusterEvalQ
clusterEvalQ(cl, library(rstan))
clusterEvalQ(cl, library(Rcpp))
clusterEvalQ(cl, library(mclust))
clusterEvalQ(cl, library(mvtnorm))
clusterEvalQ(cl, library(edgeR))
clusterEvalQ(cl, library(capushe))
clusterEvalQ(cl, library(clusterGeneration))
clusterEvalQ(cl, library(coda))
# Calculating normalization factors
if(is.na(normalize) == FALSE) {
if (!require(edgeR)) install.packages('edgeR') # loading needed package
library(edgeR)
norm_factors<-log(as.vector(calcNormFactors(as.matrix(dataset), method = "TMM")))
} else {norm_factors<-rep(0,d)}
MPLN_parallel = function(g){
## ** Never use set.seed(), use clusterSetRNGStream() instead,
# to set the cluster seed if you want reproducible results
# clusterSetRNGStream(cl=cl, iseed=g)
test = calling_clustering(dataset=dataset, Gmin=g, Gmax=g, n_chains=n_chains, n_iterations=n_iterations, init_method=init_method, n_init_iterations=n_init_iterations, norm_factors=norm_factors, mod=mod)
return(test)
}
# empty list to save output
parallel.Wei_2 = list()
cat("\nRunning parallel code now.")
parallel.Wei_2 = clusterMap(cl=cl,fun=MPLN_parallel, g=Gmin:Gmax)
cat("\nDone parallel code.")
stopCluster(cl)
BIC<-ICL<-AIC<-AIC3<-Djump<-DDSE<-k<-ll<-vector()
for(g in 1:(Gmax-Gmin+1)) {
ll[g]<-unlist(tail(parallel.Wei_2[[g]]$allresults$loglikelihood, n=1)) # save the final log-likelihood
k[g]<-calculate_parameters(g,dataset)
if (g==max(1:(Gmax-Gmin+1))){ # starting model selection
bic<-BIC_function(ll=ll,k=k, n=n, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax, dataset=dataset)
icl<-ICL_function(bIc=bic, gmin=Gmin, gmax=Gmax, run=parallel.Wei_2, dataset=dataset)
aic<-AIC_function(ll=ll,k=k, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax, dataset=dataset)
aic3<-AIC3_function(ll=ll,k=k, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax, dataset=dataset)
}
}
# for Djump and DDSE
if((Gmax-Gmin+1) > 10 ) {
if (!require(capushe)) install.packages('capushe') # loading needed package
library(capushe)
# adapted based on HTSCluster package 2.0.8 (25 Oct 2016)
PMM<-allruns
runs <- Gmin:Gmax
Gmax <- Gmax
logLike.final <- suppressWarnings(do.call("cbind", lapply(PMM, function(x) x$loglikelihood))) #gives log-likelihood for each cluster at each run
logLike.val <- apply(logLike.final,1,max)
message("Note: diagnostic plots for results corresponding to model selection via slope heuristics (Djump and DDSE) should be examined to ensure that sufficiently complex models have been considered.")
Kchoice <- Gmin:Gmax
k <- k # number of parameters
mat <- cbind(Kchoice, k/n, k/n, -logLike.val)
ResCapushe <- capushe(mat, n)
DDSEmodel<- ResCapushe@DDSE@model
Djumpmodel<- ResCapushe@Djump@model
final<-proc.time()-ptm
RESULTS <- list(dataset= dataset,
dimensionality = d,
normalization_factors=norm_factors,
Gmin = Gmin,
Gmax = Gmax,
initalization_method = init_method,
allresults = parallel.Wei_2,
loglikelihood = ll,
n_parameters = k,
truelabels = membership,
ICL.all = icl,
BIC.all = bic,
AIC.all = aic,
AIC3.all = aic3,
SlopeHeuristics = ResCapushe,
Djumpmodelselected = ResCapushe@Djump@model,
DDSEmodelselected = ResCapushe@DDSE@model,
totaltime = final)
# end of Djump and DDSE
} else {
final<-proc.time()-ptm
RESULTS <- list(dataset= dataset,
dimensionality = d,
normalization_factors=norm_factors,
Gmin = Gmin,
Gmax = Gmax,
initalization_method = init_method,
allresults = parallel.Wei_2,
loglikelihood = ll,
n_parameters = k,
truelabels = membership,
ICL.all = icl,
BIC.all = bic,
AIC.all = aic,
AIC3.all = aic3,
totaltime = final)
}
class(RESULTS) <- "MPLN"
return(RESULTS)
}
#### function ####
Datagenerator<-function(i, N, d, pi_g, means, sigmas){
set.seed(i)
z<-t(rmultinom(N,size=1,pi_g))
if (!require(mclust)) install.packages("mvtnorm")
if (!require(mclust)) install.packages("clusterGeneration")
source("https://bioconductor.org/biocLite.R")
if (!require(mclust)) biocLite("edgeR")
library("edgeR")
y<-theta<-n_g <- vector("list", length = length(pi_g))
theta2<-matrix(NA,ncol=d,nrow=N) # for visualization only
for (i in 1:length(pi_g)){
n_g[[i]]<-which(z[,i]==1)
theta[[i]]<-rmvnorm(length(n_g[[i]]), mean=means[i,], sigma=sigmas[((i-1)*d+1):(i*d),])
theta2[n_g[[i]],]<-rmvnorm(length(n_g[[i]]), mean=means[i,], sigma=sigmas[((i-1)*d+1):(i*d),])
}
y<-matrix(NA,ncol=d,nrow=N)
for (i in 1:N){
for (j in 1:d){
y[i,j]<-rpois(1,exp(theta2[i,j]))
}
}
norms <- log(calcNormFactors(y))
#generating counts with norm factors
y2<-matrix(NA,ncol=d,nrow=N)
for (i in 1:N){
for (j in 1:d){
y2[i,j]<-rpois(1,exp(theta2[i,j]+norms[j]))
}
}
Pairs_plot=function(){
pairs(log(y2), col=map(z)+1, main="Pairs plot of log-transformed data")
}
results<-list(dataset=y2,
truemembership=map(z),
truenormfactors =norms,
observations = N,
dimensionality = d,
pi_g = pi_g,
means = means,
sigmas = sigmas,
Visual=Pairs_plot())
class(results) <- "MPLN_datagenerator"
return(results)
}
