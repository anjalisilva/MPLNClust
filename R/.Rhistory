z=initialization$probaPost
}
while(!conv_outer){
for(g in 1:G){
obs[g]<-sum(z[,g]) # number of observations in each group
PI[g]<-obs[g]/n  # obtain probability of each group
}
theta_Stan<-E_theta2<-list()
rstan_results<-stanrun(model=mod, gmin=1,gmax=G,y=y,mu_all_outer=mu_all_outer, it_outer=it_outer, sigma_all_outer=sigma_all_outer, numb_iterations=numb_iterations, n_chain=n_chain, normalizefacs=normalizefac)
fit = rstan_results$fitrstan
numb_iterations = rstan_results$numb_iterations
for (g in 1:G){
tt<-as.matrix(fit[[g]])
theta_Stan[[g]]<-matrix(NA,nrow=n,ncol=d)
E_theta2[[g]]<-list()
for (i in 1:n){
zz<-c(1:(d-1))*n+i
theta_mat<-tt[,c(i,zz)]
theta_Stan[[g]][i,]<-colMeans(theta_mat)
E_theta2[[g]][[i]]<-z[i,g]*t(tt[,c(i,zz)])%*%tt[,c(i,zz)]/((0.5*numb_iterations)*n_chain)
}
mu_g[g,]<-colSums(z[,g]*theta_Stan[[g]])/sum(z[,g])
Sig_g[((g-1)*d+1):(g*d),]<-Reduce("+",E_theta2[[g]])/sum(z[,g])-mu_g[g,]%*%t(mu_g[g,])
}
mu_all_outer[[it_outer]]<-mu_g
sigma_all_outer[[it_outer]]<-Sig_g
logL[it_outer]<-calc_likelihood(z=z, PI=PI, y=y, mu_g=mu_all_outer[[it_outer]], G=G, Sig_g=sigma_all_outer[[it_outer]], theta_Stan=theta_Stan, normalizefactors=normalizefac)
# convergence of outer loop
norm_mu_outer[it_outer]<-norm((mu_all_outer[[it_outer]]-mu_all_outer[[it_outer-1]]),type="F")
norm_sigma_outer[it_outer]<-norm(sigma_all_outer[[it_outer]]-sigma_all_outer[[it_outer-1]],type="F")
median_mu_outer[[it_outer]]<-median(norm_mu_outer, na.rm = TRUE)
median_sigma_outer[[it_outer]]<-median(norm_sigma_outer, na.rm = TRUE)
#par(mfrow=c(1,2))
#plot(norm_mu_outer, main=paste0("Norm outer mean, G=", G), type="l", ylab="median(norm_mu_outer)", xlab="iterations")
#plot(norm_sigma_outer, main=paste0("Norm outer sigma, G=", G), type="l", ylab="median(norm_sigma_outer)", xlab="iterations")
threshold_outer<-2
if(it_outer>(threshold_outer+1)){
cat("\nMedian difference of mean and sigma in outer loop respectively ", c(abs(median_mu_outer[[it_outer-threshold_outer]]-median_mu_outer[[it_outer]])))
if( ( (abs(median_mu_outer[[it_outer-threshold_outer]]-median_mu_outer[[it_outer]])<5) && (abs(median_sigma_outer[[it_outer-threshold_outer]]-median_sigma_outer[[it_outer]])<5) ) || it_outer>100){
cat("\nConvergence of mu and sigma at outer loop iteration ", it_outer) # take out absolute value
programclust<-vector()
programclust<-map(z)
# checking for spurious clusters and getting rid of them
#keep<-as.numeric(names(which(table(programclust)>5)))
#if ( (length(keep) !=length(unique(programclust))) && (length(keep) !=0) ){
#  z<-as.matrix(z[,keep])
#  z<-z/rowSums(z)
#  programclust<-map(z)
#}
# checking for empty clusters
J <- 1:ncol(z)
K <- as.logical(match(J, sort(unique(programclust)), nomatch = 0))
if(length(J[!K])>0){ # J[!K] tells which are empty clusters
z<-z[,-J[!K]]
programclust<-map(z)
}
conv_outer<-1
}
}
# if running for initialization, need to stop after 10 iterations
if(it_outer==10 && all(is.na(initialization) !=TRUE)){
if(all(initialization == "init")){
programclust<-vector()
programclust<-map(z)
conv_outer<-1
}
}
if(conv_outer!=1){ # only update until convergence, not after
z<-zvalue_calculation(theta_Stan=theta_Stan,y=y,G=G,mu_g=mu_g,Sig_g=Sig_g,PI=PI, normalizefactors=normalizefac)
it_outer<-it_outer+1 # updating outer loop iteration
numb_iterations = numb_iterations+10
}
} # end of outer loop
results <- list(finalmu=mu_all_outer[[it_outer]]+ matrix(rep(normalizefac,nrow(mu_all_outer[[it_outer]])),byrow=TRUE,ncol=ncol(mu_all_outer[[it_outer]])),
finalsigma=sigma_all_outer[[it_outer]],
allmu = lapply(mu_all_outer, function(x) (x+matrix(rep(normalizefac,nrow(mu_all_outer[[it_outer]])),byrow=TRUE,ncol=ncol(mu_all_outer[[it_outer]])))),
allsigma = sigma_all_outer,
clusterlabels = programclust,
iterations = it_outer,
proportion = PI,
loglikelihood = logL,
probaPost = z,
stanresults = fit)
class(results) <- "MPLNcluster"
return(results)
} # ending the function
calling_clustering = function(y, Gmin, Gmax, n_chain, numb_iterations=NA, init_method=NA, init_iterations=NA, norm_factors, mod){
ptm_inner = proc.time()
for (gmodel in 1:(Gmax-Gmin+1)){
if(length(1:(Gmax-Gmin+1)) == Gmax){
clustersize = gmodel
}else if(length(1:(Gmax-Gmin+1)) < Gmax){
clustersize = seq(Gmin, Gmax, 1)[gmodel]
}
if(init_iterations!=0){
#cat("\nRunning initialization for G =", clustersize)
initializeruns=initializationrun(gmodel=clustersize, y=y, init_method=init_method, init_iterations=init_iterations, n_chain=n_chain, numb_iterations=numb_iterations, initialization=NA, normalizefactors=norm_factors, mod=mod)
#cat("\nInitialization done for G =", clustersize)
#cat("\nRunning clustering for G =", clustersize)
allruns=cluster_mpln(y=y,z=NA,G=clustersize,n_chain=n_chain,numb_iterations=numb_iterations, initialization=initializeruns,normalizefac=norm_factors, mod=mod)
#cat("\nClustering done for G =", clustersize)
}else if(init_iterations == 0){
#cat("\nNo initialization done for G =", clustersize)
#cat("\nRunning clustering for G =", clustersize)
allruns=cluster_mpln(y=y, z=unmap(kmeans(log(y+1/3),clustersize)$cluster), G=clustersize, n_chain=n_chain, numb_iterations=numb_iterations, initialization=NA, normalizefac=norm_factors, mod=mod)
#cat("\nClustering done for G =", clustersize)
}
}
final_inner<-proc.time()-ptm_inner
RESULTS <- list(  gmin = Gmin,
gmax = Gmax,
initalization_method = init_method,
allresults = allruns,
totaltime = final_inner)
class(RESULTS) <- "MPLN"
return(RESULTS)
}
main_mpln<-function(i, y, membership, Gmin, Gmax, n_chain, numb_iterations=NA, init_method=NA, init_iterations=NA, normalize=NA){
ptm<-proc.time()
if (typeof(y) != "double" & typeof(y) != "integer"){
stop("Dataset type needs to be integer");}
if (Gmax<Gmin){
stop("Gmax cannot be less than Gmin");}
if(is.na(numb_iterations)) numb_iterations <- 1000
#if(is.na(n_chain) || n_chain<3) {
#  n_chain <- 3
#  print("Recommended number of chains is minimum 3. n_chain' set to 3")}
if(numb_iterations<40){
stop("RStan numb_iterations argument should be greater than 40");}
if((is.na(init_iterations) != TRUE && init_iterations == !0) && is.na(init_method) == TRUE){
stop("Number of initialization iterations specified, but no initialization method selected");}
d<-ncol(y)
n<-nrow(y)
if(all(is.na(membership)!=TRUE) && length(membership)!=n){
stop("Length of membership character vector and sample size of dataset should match");}
if(all(is.na(membership)!=TRUE) && all((diff(sort(unique(membership)))==1)!=TRUE) ){
stop("Cluster memberships in the membership vector are missing a cluster, e.g. 1,3,4,5,6 is missing cluster 2");}
if(length(which(apply(y, 1, function(x) all(x==0))==TRUE))!=0){
cat("\nDataset row(s)", c(which(apply(y, 1, function(x) all(x==0))==TRUE)), "will be removed as this/these contain(s) all zeros")
if(all(is.na(membership)==FALSE)){membership<-membership[-c(which(apply(y, 1, function(x) all(x==0))==TRUE))]}
y<-y[-c(which(apply(y, 1, function(x) all(x==0))==TRUE)),]
n<-nrow(y)
}
if(all(is.na(membership)==TRUE)){
membership<-"Not provided"}
if (Gmax > n){
stop("Gmax cannot be larger than n");}
if(is.na(normalize) == FALSE) {
if (!require(edgeR)) install.packages('edgeR') # loading needed package
library(edgeR)
norm_factors<-log(as.vector(calcNormFactors(as.matrix(y), method = "TMM")))
} else {norm_factors<-rep(0,d)}
#cat("\nNormalize factors in main_mpln are: ",norm_factors)
MPLN_parallel = function(g){
## ** Never use set.seed(), use clusterSetRNGStream() instead,
# to set the cluster seed if you want reproducible results
#clusterSetRNGStream(cl=cl, iseed=g)
test = calling_clustering(y=y, Gmin=g, Gmax=g, n_chain=n_chain, numb_iterations=numb_iterations, init_method=init_method, init_iterations=init_iterations, norm_factors=norm_factors, mod=mod)
return(test)
}
#print("Done MPLN_parallel")
# empty list to save output
parallel.Wei_2 = list()
cat("\nRunning parallel code now.")
parallel.Wei_2 = clusterMap(cl=cl,fun=MPLN_parallel, g=Gmin:Gmax)
cat("\nDone parallel code.")
BIC<-ICL<-AIC<-AIC3<-Djump<-DDSE<-k<-ll<-vector()
for(g in 1:(Gmax-Gmin+1)) {
ll[g]<-unlist(tail(parallel.Wei_2[[g]]$allresults$loglikelihood, n=1)) # save the final log-likelihood
k[g]<-calculate_parameters(g,y)
if (g==max(1:(Gmax-Gmin+1))){ # starting model selection
bic<-BIC_function(ll=ll,k=k, n=n, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax)
icl<-ICL_function(bIc=bic, gmin=Gmin, gmax=Gmax, run=parallel.Wei_2)
aic<-AIC_function(ll=ll,k=k, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax )
aic3<-AIC3_function(ll=ll,k=k, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax)
}
}
# for Djump and DDSE
if((Gmax-Gmin+1) > 10 ) {
if (!require(capushe)) install.packages('capushe') # loading needed package
library(capushe)
# adapted based on HTSCluster package 2.0.8 (25 Oct 2016)
PMM<-allruns
runs <- Gmin:Gmax
Gmax <- Gmax
logLike.final <- suppressWarnings(do.call("cbind", lapply(PMM, function(x) x$loglikelihood))) #gives log-likelihood for each cluster at each run
logLike.val <- apply(logLike.final,1,max)
message("Note: diagnostic plots for results corresponding to model selection via slope heuristics (Djump and DDSE) should be examined to ensure that sufficiently complex models have been considered.")
Kchoice <- Gmin:Gmax
k <- k # number of parameters
mat <- cbind(Kchoice, k/n, k/n, -logLike.val)
ResCapushe <- capushe(mat, n)
DDSEmodel<- ResCapushe@DDSE@model
Djumpmodel<- ResCapushe@Djump@model
final<-proc.time()-ptm
RESULTS <- list(dataset= y,
dimensionality = d,
normalization_factors=norm_factors,
gmin = Gmin,
gmax = Gmax,
initalization_method = init_method,
allresults = parallel.Wei_2,
loglikelihood = ll,
numbofparameters = k,
truelabels = membership,
ICL.all = icl,
BIC.all = bic,
AIC.all = aic,
AIC3.all = aic3,
SlopeHeuristics = ResCapushe,
Djumpmodelselected = ResCapushe@Djump@model,
DDSEmodelselected = ResCapushe@DDSE@model,
totaltime = final)
} else {# end of Djump and DDSE
final<-proc.time()-ptm
RESULTS <- list(dataset= y,
dimensionality = d,
normalization_factors=norm_factors,
gmin = Gmin,
gmax = Gmax,
initalization_method = init_method,
allresults = parallel.Wei_2,
loglikelihood = ll,
numbofparameters = k,
truelabels = membership,
ICL.all = icl,
BIC.all = bic,
AIC.all = aic,
AIC3.all = aic3,
SlopeHeuristics = "Not used",
Djumpmodelselected = "Not used",
DDSEmodelselected = "Not used",
totaltime = final)
}
class(RESULTS) <- "MPLN"
return(RESULTS)
}
################################################
#### Running data ####
# Making RStan model #
mod = stan_model("MPLN.stan")
# running code in parallel
if (!require(parallel)) install.packages('parallel') # loading needed package
# Calculate the number of cores
no_cores = detectCores()-1
# Initiate cluster
cl = makeCluster(no_cores)
print("Doing clusterExport")
clusterExport(cl,c("i", "mod", "NBinom_datasets_2clusters","zvalue_calculation", "calc_likelihood", "stanrun", "initializationrun", "BIC_function","ICL_function","AIC_function","AIC3_function", "calculate_parameters", "cluster_mpln", "calling_clustering"))
print("Doing clusterEvalQ")
#other packages need to be downloaded using clusterEvalQ
clusterEvalQ(cl, library(rstan))
clusterEvalQ(cl, library(Rcpp))
clusterEvalQ(cl, library(mclust))
clusterEvalQ(cl, library(mvtnorm))
clusterEvalQ(cl, library(edgeR))
clusterEvalQ(cl, library(capushe))
clusterEvalQ(cl, library(clusterGeneration))
clusterEvalQ(cl, library(coda))
NegBinom_sim_2clusters<-list() # list for saving data results
for (i in 1:numbdatasets){
set.seed(i)
cat("\n Running dataset: ", i)
NegBinom_sim_2clusters[[i]]<-main_mpln(y=NBinom_datasets_2clusters[[i]]$dataset, Gmin=1, Gmax=2, n_chain=3, numb_iterations=300, membership=NA, init_method="kmeans", init_iterations=3, normalize="TMM")
}
source("PackageCheck.R")
LoadCheckPkg(pckgs=c("mvtnorm","mclust","coda","capushe"))
# loading needed packages
LoadCheckPkg(pckgs=c("mvtnorm","mclust","coda","capushe","edgeR","clusterGeneration","pheatmap",
"RColorBrewer","gplots","rstan","Rcpp","parallel"))
source("MPLNDataGenerator.R")
source("AIC3Function.R")
source("AICFunction.R")
source("BICFunction.R")
source("CalcLikelihood.R")
source("CalculateParameters.R")
source("CallingClustering.R")
source("ClusterMPLN.R")
source("ICLFunction.R")
source("InitializationRun.R")
source("MPLNClustering.R")
source("MPLNDataGenerator.R")
source("PackageCheck.R")
source("StanRun.R")
source("ZValueCalculation")
setwd("/Volumes/GoogleDrive/My Drive/UGuelph/Analysis_Anjali'sLaptop/All algorithms (Monte Carlo EM)/mixtures_of_MPLN/Git/GitHub/R")
source("ZValueCalculation")
source("AIC3Function.R")
source("AICFunction.R")
source("BICFunction.R")
source("CalcLikelihood.R")
source("CalculateParameters.R")
source("CallingClustering.R")
source("ClusterMPLN.R")
source("ICLFunction.R")
source("InitializationRun.R")
source("MPLNClustering.R")
source("MPLNDataGenerator.R")
source("PackageCheck.R")
source("StanRun.R")
source("ZValueCalculation")
# Generating data
true_mu1 <- c(6.5,6,6,6,6,6)
true_mu2 <- c(2,2.5,2,2,2,2)
true_sigma1 <- diag(6) * 2
true_sigma2 <- diag(6)
simulated_counts <- Datagenerator(i = 1, N = 50, d = 6, pi_g = c(0.79,0.21), means = rbind(true_mu1,true_mu2), sigmas = rbind(true_sigma1,true_sigma2))
testing_dataset <- simulated_counts$dataset # Assign test dataset using the variable name 'testing_dataset'
source("AIC3Function.R")
source("AICFunction.R")
source("BICFunction.R")
source("CalcLikelihood.R")
source("CalculateParameters.R")
source("CallingClustering.R")
source("ClusterMPLN.R")
source("ICLFunction.R")
source("InitializationRun.R")
source("MPLNClustering.R")
source("MPLNDataGenerator.R")
source("PackageCheck.R")
source("StanRun.R")
source("ZValueCalculation")
# Generating data
true_mu1 <- c(6.5,6,6,6,6,6)
true_mu2 <- c(2,2.5,2,2,2,2)
true_sigma1 <- diag(6) * 2
true_sigma2 <- diag(6)
simulated_counts <- Datagenerator(i = 1, N = 50, d = 6, pi_g = c(0.79,0.21), means = rbind(true_mu1,true_mu2), sigmas = rbind(true_sigma1,true_sigma2), ProduceImage="Yes")
testing_dataset <- simulated_counts$dataset # Assign test dataset using the variable name 'testing_dataset'
paste0(pathNow,"/PairsPlot.png")
pathNow<-getwd()
paste0(pathNow,"/PairsPlot.png")
source("MPLNDataGenerator.R")
testing_dataset <- simulated_counts$dataset # Assign test dataset using the variable name 'testing_dataset'
simulated_counts <- Datagenerator(i = 1, N = 50, d = 6, pi_g = c(0.79,0.21), means = rbind(true_mu1,true_mu2), sigmas = rbind(true_sigma1,true_sigma2), ProduceImage="Yes")
LoadCheckPkg(pckgs=c("mvtnorm","clusterGeneration","edgeR"))
source("MPLNDataGenerator.R")
true_mu1 <- c(6.5,6,6,6,6,6)
true_mu2 <- c(2,2.5,2,2,2,2)
true_sigma1 <- diag(6) * 2
true_sigma2 <- diag(6)
simulated_counts <- Datagenerator(i = 1, N = 50, d = 6, pi_g = c(0.79,0.21), means = rbind(true_mu1,true_mu2), sigmas = rbind(true_sigma1,true_sigma2), ProduceImage="Yes")
simulated_counts <- Datagenerator(i = 1, N = 50, d = 6, pi_g = c(0.79,0.21), means = rbind(true_mu1,true_mu2), sigmas = rbind(true_sigma1,true_sigma2), ProduceImage="Yes")
testing_dataset <- simulated_counts$dataset # Assign test dataset using the variable name 'testing_dataset'
clus_results <- MPLNClustering(dataset = testing_dataset, Gmin = 1, Gmax = 2, n_chains = 3, n_iterations=100, membership = NA, init_method = "kmeans", n_init_iterations = 1, normalize = "TMM")
source("ZValueCalculation")
source("StanRun.R")
zvalue_calculation<-function(theta_Stan,y,G,mu_g,Sig_g,PI, normalizefactors){
d<-ncol(y)
n<-nrow(y)
forz<-matrix(NA,ncol=G,nrow=n)
for (g in 1:G){
for (i in 1:n){
x<-theta_Stan[[g]][i,]
# for zig calculation (the numerator part)
forz[i,g]<-PI[g]*exp(t(y[i,])%*%(x+normalizefactors)-sum(exp(x+normalizefactors))-sum(lfactorial(y[i,]))-
d/2*log(2*pi)-1/2*log(det(Sig_g[((g-1)*d+1):(g*d),]))-0.5*t(x-mu_g[g,])%*%solve(Sig_g[((g-1)*d+1):(g*d),])%*%
(x-mu_g[g,]))
}
# check which forz == 0 and rowSums(forz)==0 and which of these
# have both equalling to 0 (because 0/0 = NaN)
if (G==1){
errorpossible<-Reduce(intersect, list(which(forz==0),which(rowSums(forz)==0)))
zvalue<-forz/rowSums(forz)
zvalue[errorpossible,]<-1
}else {zvalue<-forz/rowSums(forz)}
}
# check which forz == 0 and rowSums(forz)==0 and which of these
# have both equalling to 0 (because 0/0 =NaN)
if (G==1){
errorpossible<-Reduce(intersect, list(which(forz==0),which(rowSums(forz)==0)))
zvalue<-forz/rowSums(forz)
zvalue[errorpossible,]<-1
}else {zvalue<-forz/rowSums(forz)}
return(zvalue)
}
source("ZValueCalculation.R")
testing_dataset <- simulated_counts$dataset # Assign test dataset using the variable name 'testing_dataset'
clus_results <- MPLNClustering(dataset = testing_dataset, Gmin = 1, Gmax = 2, n_chains = 3, n_iterations=100, membership = NA, init_method = "kmeans", n_init_iterations = 1, normalize = "TMM")
testing_dataset
dataset = testing_dataset
dataset = testing_dataset
Gmin = 1
Gmax = 2
n_chains = 3
n_iterations=100
membership = NA
init_method = "kmeans"
n_init_iterations = 1
normalize = "TMM"
ptm<-proc.time()
if (typeof(dataset) != "double" & typeof(dataset) != "integer"){
stop("Dataset type needs to be integer");}
if (Gmax<Gmin){
stop("Gmax cannot be less than Gmin");}
if(is.na(n_iterations)) n_iterations <- 1000
if(is.na(n_chains) || n_chains<3) {
n_chains <- 3
print("Recommended number of chains is minimum 3. 'n_chains' set to 3")}
if(n_iterations<40){
stop("RStan n_iterations argument should be greater than 40");}
if((is.na(n_init_iterations) != TRUE && n_init_iterations == !0) && is.na(init_method) == TRUE){
stop("Number of initialization iterations specified, but no initialization method selected");}
d<-ncol(dataset)
n<-nrow(dataset)
if(all(is.na(membership)!=TRUE) && length(membership)!=n){
stop("Length of membership character vector and sample size of dataset should match");}
if(all(is.na(membership)!=TRUE) && all((diff(sort(unique(membership)))==1)!=TRUE) ){
stop("Cluster memberships in the membership vector are missing a cluster, e.g. 1,3,4,5,6 is missing cluster 2");}
if(length(which(apply(dataset, 1, function(x) all(x==0))==TRUE))!=0){
cat("\nDataset row(s)", c(which(apply(dataset, 1, function(x) all(x==0))==TRUE)),
"will be removed as this/these contain(s) all zeros")
if(all(is.na(membership)==FALSE)){membership<-membership[-c(which(apply(dataset, 1, function(x) all(x==0))==TRUE))]}
dataset<-dataset[-c(which(apply(dataset, 1, function(x) all(x==0))==TRUE)),]
n<-nrow(dataset)
}
if(all(is.na(membership)==TRUE)){
membership<-"Not provided"}
if (Gmax > n){
stop("Gmax cannot be larger than n");}
LoadCheckPkg(pckgs=c("mvtnorm","mclust","coda","capushe","edgeR","clusterGeneration",
"pheatmap","RColorBrewer","gplots","rstan","Rcpp","parallel"))
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
mod <<- stan_model("MPLN.stan")
no_cores = detectCores()
cl = makeCluster(no_cores-1)
clusterExport(cl,c("mod", "testing_dataset","zvalue_calculation", "calc_likelihood", "stanrun",
"initializationrun", "BIC_function","ICL_function","AIC_function","AIC3_function", "calculate_parameters",
"cluster_mpln", "calling_clustering"))
# Packages need to be downloaded using clusterEvalQ
clusterEvalQ(cl, library(rstan))
clusterEvalQ(cl, library(Rcpp))
clusterEvalQ(cl, library(mclust))
clusterEvalQ(cl, library(mvtnorm))
clusterEvalQ(cl, library(edgeR))
clusterEvalQ(cl, library(capushe))
clusterEvalQ(cl, library(clusterGeneration))
clusterEvalQ(cl, library(coda))
clusterEvalQ(cl, library(pheatmap))
clusterEvalQ(cl, library(RColorBrewer))
clusterEvalQ(cl, library(gplots))
# Calculating normalization factors
if(is.na(normalize) == FALSE) {
norm_factors<-log(as.vector(calcNormFactors(as.matrix(dataset), method = "TMM")))
} else {norm_factors<-rep(0,d)}
MPLN_parallel = function(g){
## ** Never use set.seed(), use clusterSetRNGStream() instead,
# to set the cluster seed if you want reproducible results
# clusterSetRNGStream(cl=cl, iseed=g)
test = calling_clustering(dataset=dataset, Gmin=g, Gmax=g, n_chains=n_chains, n_iterations=n_iterations,
init_method=init_method, n_init_iterations=n_init_iterations, norm_factors=norm_factors, mod=mod)
return(test)
}
parallel.Wei_2 = list()
cat("\nRunning parallel code now.")
parallel.Wei_2 = clusterMap(cl=cl,fun=MPLN_parallel, g=Gmin:Gmax)
cl
MPLN_parallel
Gmin:Gmax
g=Gmin:Gmax
parallel.Wei_2 = clusterMap(cl=cl,fun=MPLN_parallel, g=Gmin:Gmax)
cat("\nDone parallel code.")
clusterMap
MPLN_parallel
test = calling_clustering(dataset=dataset, Gmin=g, Gmax=g, n_chains=n_chains, n_iterations=n_iterations,
init_method=init_method, n_init_iterations=n_init_iterations, norm_factors=norm_factors, mod=mod)
calling_clustering
calling_clustering
source("CallingClustering.R")
testing_dataset <- simulated_counts$dataset # Assign test dataset using the variable name 'testing_dataset'
clus_results <- MPLNClustering(dataset = testing_dataset, Gmin = 1, Gmax = 2, n_chains = 3, n_iterations = 100, membership = NA, init_method = "kmeans", n_init_iterations = 1, normalize = "TMM")
source("AIC3Function.R")
source("AICFunction.R")
source("BICFunction.R")
source("CalcLikelihood.R")
source("CalculateParameters.R")
source("CallingClustering.R")
source("ClusterMPLN.R")
source("ICLFunction.R")
source("InitializationRun.R")
source("MPLNClustering.R")
source("MPLNDataGenerator.R")
source("PackageCheck.R")
source("StanRun.R")
source("ZValueCalculation.R")
# Generating data
source("AIC3Function.R")
source("AICFunction.R")
source("BICFunction.R")
source("CalcLikelihood.R")
source("CalculateParameters.R")
source("CallingClustering.R")
source("ClusterMPLN.R")
source("ICLFunction.R")
source("InitializationRun.R")
source("MPLNClustering.R")
source("MPLNDataGenerator.R")
source("PackageCheck.R")
source("StanRun.R")
source("ZValueCalculation.R")
# Generating data
true_mu1 <- c(6.5,6,6,6,6,6)
true_mu2 <- c(2,2.5,2,2,2,2)
true_sigma1 <- diag(6) * 2
true_sigma2 <- diag(6)
simulated_counts <- Datagenerator(i = 1, N = 50, d = 6, pi_g = c(0.79,0.21), means = rbind(true_mu1,true_mu2), sigmas = rbind(true_sigma1,true_sigma2), ProduceImage="Yes")
testing_dataset <- simulated_counts$dataset # Assign test dataset using the variable name 'testing_dataset'
testing_dataset
clus_results <- MPLNClustering(dataset = testing_dataset, Gmin = 1, Gmax = 2, n_chains = 3, n_iterations = 100, membership = NA, init_method = "kmeans", n_init_iterations = 1, normalize = "TMM")
warnings()
clus_results
