true_mu2 <- rep(1000,6)
means1=list(true_mu1,true_mu2)
################################################
#### Generating Data ####
NBinom_datasets_2clusters<-list() # G=2
for (i in 1:numbdatasets){
set.seed(i)
NBinom_datasets_2clusters[[i]]<-Datagenerator_NBinom(i=i, N=N1, d=d1, pi_g=pi_g1, means=means1)
}
################################################
#### MPLN Functions ####
zvalue_calculation<-function(theta_Stan,y,G,mu_g,Sig_g,PI, normalizefactors){
d<-ncol(y)
n<-nrow(y)
forz<-matrix(NA,ncol=G,nrow=n)
for (g in 1:G){
for (i in 1:n){
x<-theta_Stan[[g]][i,]
# for zig calculation (the numerator part)
forz[i,g]<-PI[g]*exp(t(y[i,])%*%(x+normalizefactors)-sum(exp(x+normalizefactors))-sum(lfactorial(y[i,]))-
d/2*log(2*pi)-1/2*log(det(Sig_g[((g-1)*d+1):(g*d),]))-0.5*t(x-mu_g[g,])%*%solve(Sig_g[((g-1)*d+1):(g*d),])%*%(x-mu_g[g,]))
}
# check which forz == 0 and rowSums(forz)==0 and which of these
# have both equalling to 0 (because 0/0 =NaN)
if (G==1){
errorpossible<-Reduce(intersect, list(which(forz==0),which(rowSums(forz)==0)))
zvalue<-forz/rowSums(forz)
zvalue[errorpossible,]<-1
}else {zvalue<-forz/rowSums(forz)}
}
# check which forz == 0 and rowSums(forz)==0 and which of these
# have both equalling to 0 (because 0/0 =NaN)
if (G==1){
errorpossible<-Reduce(intersect, list(which(forz==0),which(rowSums(forz)==0)))
zvalue<-forz/rowSums(forz)
zvalue[errorpossible,]<-1
}else {zvalue<-forz/rowSums(forz)}
return(zvalue)
}
calc_likelihood<-function(z, PI, y, mu_g, G, Sig_g, theta_Stan, normalizefactors){
n<-nrow(y)
like<-matrix(NA, nrow=n, ncol=G)
for (g in 1:G){
for (i in 1:n){
x<-theta_Stan[[g]][i,]
d<-ncol(y)
like[i,g]<-(z[i,g] *(log(PI[g]) +
t(y[i,])%*%(x+normalizefactors)-sum(exp(x+normalizefactors))-sum(lfactorial(y[i,]))-
d/2*log(2*pi)-1/2*log(det(Sig_g[((g-1)*d+1):(g*d),]))-0.5*t(x-mu_g[g,])%*%solve(Sig_g[((g-1)*d+1):(g*d),])%*%(x-mu_g[g,])))
}
}
loglike<-sum(rowSums(like))
return(loglike)
}
stanrun<-function(model, gmin, gmax, y, mu_all_outer, it_outer, sigma_all_outer, numb_iterations, n_chain=n_chain, normalizefacs){
fitrstan<-list()
d<-ncol(y)
for (g in gmin:gmax){
data1=list(d=ncol(y),N=nrow(y),y=y,mu=mu_all_outer[[it_outer-1]][g,],Sigma=sigma_all_outer[[it_outer-1]][((g-1)*d+1):(g*d),], normfactors=as.vector(normalizefacs))
stanproceed<-0
try=1
while (!stanproceed){
cat("\nRstan generating sample at outer iteration", it_outer, "for g: ",g , "try: ", try)
cat("\nNumber of iterations is", numb_iterations, "\n")
fitrstan[[g]]<-sampling(object=model,
data=data1,
iter=numb_iterations, chains = n_chain, verbose=FALSE, refresh=-1)
if (all(summary(fitrstan[[g]])$summary[,"Rhat"] < 1.1) == TRUE && all(summary(fitrstan[[g]])$summary[,"n_eff"]>100) == TRUE){
stanproceed<-1
} else if(all(summary(fitrstan[[g]])$summary[,"Rhat"] < 1.1) != TRUE || all(summary(fitrstan[[g]])$summary[,"n_eff"]>100) != TRUE){
if(try == 10){ # stop after 10 tries
stanproceed = 1
}
numb_iterations = numb_iterations+100
try=try+1
}
}
} # close g loop
results <- list(fitrstan = fitrstan,
numb_iterations = numb_iterations)
class(results) <- "RStan"
return(results)
return(results)
}
initializationrun<-function(gmodel, y, init_method, init_iterations, n_chain, numb_iterations, initialization=NA, normalizefactors, mod){
z<-init_runs<-list()
logL_init<-vector()
n<-nrow(y)
d<-ncol(y)
for(iterations in 1:init_iterations){
if (init_method=="kmeans" | is.na(init_method)){
if (!require(mclust)) suppressWarnings(install.packages('mclust')) # loading needed packages
suppressWarnings(library(mclust))
z[[iterations]]<-unmap(kmeans(log(y+1/3),gmodel)$cluster)
}else if (init_method=="random"){
if(gmodel==1){ # generating z if g=1
z[[iterations]] <- as.matrix(rep.int(1, times=n), ncol=gmodel, nrow=n)
} else { # generating z if g>1
z_conv=0
while(!z_conv){ # ensure that dimension of z is same as G (i.e.
# if one column contains all 0s, then generate z again)
z[[iterations]] <- t(rmultinom(n, size = 1, prob=rep(1/gmodel,gmodel)))
if(length(which(colSums(z[[iterations]])>0)) ==gmodel){
z_conv=1
}
}
}
}else if (init_method=="medoids"){
if (!require(cluster)) install.packages('cluster')
library(cluster)
if (!require(mclust)) suppressWarnings(install.packages('mclust')) # loading needed packages
suppressWarnings(library(mclust))
z[[iterations]]<-unmap(pam(log(y+1/3),k=gmodel)$cluster)
}else if (init_method=="clara"){
if (!require(cluster)) install.packages('cluster')
library(cluster)
z[[iterations]]<-unmap(clara(log(y+1/3),k=gmodel)$cluster)
}else if (init_method=="fanny"){
if (!require(cluster)) install.packages('cluster')
library(cluster)
z[[iterations]]<-unmap(fanny(log(y+1/3),k=gmodel)$cluster)
}
init_runs[[iterations]]=cluster_mpln(y=y,z=z[[iterations]],G=gmodel,n_chain=n_chain,numb_iterations=numb_iterations, initialization="init", normalizefac=normalizefactors, mod=mod)
logL_init[iterations] <- unlist(tail((init_runs[[iterations]]$loglikelihood), n=1))
}
initialization<-init_runs[[which(logL_init==max(logL_init, na.rm = TRUE))[1]]]
return(initialization)
}
# BIC function
BIC_function = function(ll, k, n, run, gmin, gmax){
BIC <- -2*ll+ (k* log(n))
BICmodel<-seq(gmin, gmax, 1)[grep(min(BIC,na.rm = TRUE), BIC)]
BICmodel_labels<-run[[grep(min(BIC,na.rm = TRUE), BIC)]]$allresults$clusterlabels
BICMessage<-NA
if (max(BICmodel_labels)!=BICmodel){
BICmodel<-max(BICmodel_labels)
BICMessage<-"Spurious or empty cluster resulted."
}
BICresults<-list(allBICvalues=BIC,
BICmodelselected=BICmodel,
BICmodelselected_labels=BICmodel_labels,
BICMessage=BICMessage)
class(BICresults) <- "BIC"
return(BICresults)
}
# ICL function
ICL_function = function(bIc, gmax, gmin, run){
ICL<-vector()
for (g in 1:(gmax-gmin+1)){
z<-run[[g]]$allresults$probaPost
mapz<-mclust::unmap(run[[g]]$allresults$clusterlabels)
forICL<-function(g){sum(log(z[which(mapz[,g]==1),g]))}
ICL[g] <- bIc$allBICvalues[g] + sum(sapply(1:ncol(mapz),forICL))
}
ICLmodel<-seq(gmin, gmax, 1)[grep(min(ICL, na.rm = TRUE), ICL)]
ICLmodel_labels<-run[[grep(min(ICL, na.rm = TRUE), ICL)]]$allresults$clusterlabels
ICLMessage<-NA
if (max(ICLmodel_labels)!=ICLmodel){
ICLmodel<-max(ICLmodel_labels)
ICLMessage<-"Spurious or empty cluster resulted."
}
ICLresults<-list(allICLvalues=ICL,
ICLmodelselected=ICLmodel,
ICLmodelselected_labels=ICLmodel_labels,
ICLMessage=ICLMessage)
class(ICLresults) <- "ICL"
return(ICLresults)
}
# AIC function
AIC_function = function(ll, k, run, gmin, gmax){
AIC <- -2*ll+ 2*k
AICmodel<-seq(gmin, gmax, 1)[grep(min(AIC,na.rm = TRUE), AIC)]
AICmodel_labels<-run[[grep(min(AIC,na.rm = TRUE), AIC)]]$allresults$clusterlabels
AICMessage<-NA
if (max(AICmodel_labels)!=AICmodel){
AICmodel<-max(AICmodel_labels)
AICMessage<-"Spurious or empty cluster resulted."
}
AICresults<-list(allAICvalues=AIC,
AICmodelselected=AICmodel,
AICmodelselected_labels=AICmodel_labels,
AICMessage=AICMessage)
class(AICresults) <- "AIC"
return(AICresults)
}
# AIC3 function
AIC3_function = function(ll, k, run, gmin, gmax){
AIC3 <- -2*ll+ 3*k
AIC3model<-seq(gmin, gmax, 1)[grep(min(AIC3,na.rm = TRUE), AIC3)]
AIC3model_labels<-run[[grep(min(AIC3,na.rm = TRUE), AIC3)]]$allresults$clusterlabels
AIC3Message<-NA
if (max(AIC3model_labels)!=AIC3model){
AIC3model<-max(AIC3model_labels)
AIC3Message<-"Spurious or empty cluster resulted."
}
AIC3results<-list(allAIC3values=AIC3,
AIC3modelselected=AIC3model,
AIC3modelselected_labels=AIC3model_labels,
AIC3Message=AIC3Message)
class(AIC3results) <- "AIC3"
return(AIC3results)
}
calculate_parameters<-function(g,y){
d<-ncol(y)
mu_para<-d*g
sigma_para<-(d*((d+1)/2))*g
pi_para<-g-1 # because if you have g-1 parameters, you can do 1-these to get the last one
paratotal<-mu_para+sigma_para+pi_para # total parameters are
return(paratotal)
}
cluster_mpln<-function(y,z,G,n_chain,numb_iterations, initialization, normalizefac, mod){
d<-ncol(y)
n<-nrow(y)
norm_mu_outer<-norm_sigma_outer<-vector() # for convergence calculation
median_mu_outer<-median_sigma_outer<-list()
mu_all_outer<-sigma_all_outer<-list() # for saving mu and sigma values
obs<-PI<-logL<-vector()
it_outer<-2 # the starting value of interation for outer loop
conv_outer<-0
if (all(is.na(initialization))==TRUE || all(initialization =="init")){
mu_all_outer[[1]]<-mu_g <- matrix(log(mean(y)), ncol=d, nrow=G) # mean for both t and normal distribution
sigma_all_outer[[1]]<-Sig_g <- do.call("rbind", rep(list(cov(log(y+1))*d), G)) # sig for sigma of t distribtuion
}else{
mu_all_outer[[1]]<-mu_g <- initialization$finalmu
sigma_all_outer[[1]]<-Sig_g <- initialization$finalsigma
z=initialization$probaPost
}
while(!conv_outer){
for(g in 1:G){
obs[g]<-sum(z[,g]) # number of observations in each group
PI[g]<-obs[g]/n  # obtain probability of each group
}
theta_Stan<-E_theta2<-list()
rstan_results<-stanrun(model=mod, gmin=1,gmax=G,y=y,mu_all_outer=mu_all_outer, it_outer=it_outer, sigma_all_outer=sigma_all_outer, numb_iterations=numb_iterations, n_chain=n_chain, normalizefacs=normalizefac)
fit = rstan_results$fitrstan
numb_iterations = rstan_results$numb_iterations
for (g in 1:G){
tt<-as.matrix(fit[[g]])
theta_Stan[[g]]<-matrix(NA,nrow=n,ncol=d)
E_theta2[[g]]<-list()
for (i in 1:n){
zz<-c(1:(d-1))*n+i
theta_mat<-tt[,c(i,zz)]
theta_Stan[[g]][i,]<-colMeans(theta_mat)
E_theta2[[g]][[i]]<-z[i,g]*t(tt[,c(i,zz)])%*%tt[,c(i,zz)]/((0.5*numb_iterations)*n_chain)
}
mu_g[g,]<-colSums(z[,g]*theta_Stan[[g]])/sum(z[,g])
Sig_g[((g-1)*d+1):(g*d),]<-Reduce("+",E_theta2[[g]])/sum(z[,g])-mu_g[g,]%*%t(mu_g[g,])
}
mu_all_outer[[it_outer]]<-mu_g
sigma_all_outer[[it_outer]]<-Sig_g
logL[it_outer]<-calc_likelihood(z=z, PI=PI, y=y, mu_g=mu_all_outer[[it_outer]], G=G, Sig_g=sigma_all_outer[[it_outer]], theta_Stan=theta_Stan, normalizefactors=normalizefac)
# convergence of outer loop
norm_mu_outer[it_outer]<-norm((mu_all_outer[[it_outer]]-mu_all_outer[[it_outer-1]]),type="F")
norm_sigma_outer[it_outer]<-norm(sigma_all_outer[[it_outer]]-sigma_all_outer[[it_outer-1]],type="F")
median_mu_outer[[it_outer]]<-median(norm_mu_outer, na.rm = TRUE)
median_sigma_outer[[it_outer]]<-median(norm_sigma_outer, na.rm = TRUE)
#par(mfrow=c(1,2))
#plot(norm_mu_outer, main=paste0("Norm outer mean, G=", G), type="l", ylab="median(norm_mu_outer)", xlab="iterations")
#plot(norm_sigma_outer, main=paste0("Norm outer sigma, G=", G), type="l", ylab="median(norm_sigma_outer)", xlab="iterations")
threshold_outer<-2
if(it_outer>(threshold_outer+1)){
cat("\nMedian difference of mean and sigma in outer loop respectively ", c(abs(median_mu_outer[[it_outer-threshold_outer]]-median_mu_outer[[it_outer]])))
if( ( (abs(median_mu_outer[[it_outer-threshold_outer]]-median_mu_outer[[it_outer]])<5) && (abs(median_sigma_outer[[it_outer-threshold_outer]]-median_sigma_outer[[it_outer]])<5) ) || it_outer>100){
cat("\nConvergence of mu and sigma at outer loop iteration ", it_outer) # take out absolute value
programclust<-vector()
programclust<-map(z)
# checking for spurious clusters and getting rid of them
#keep<-as.numeric(names(which(table(programclust)>5)))
#if ( (length(keep) !=length(unique(programclust))) && (length(keep) !=0) ){
#  z<-as.matrix(z[,keep])
#  z<-z/rowSums(z)
#  programclust<-map(z)
#}
# checking for empty clusters
J <- 1:ncol(z)
K <- as.logical(match(J, sort(unique(programclust)), nomatch = 0))
if(length(J[!K])>0){ # J[!K] tells which are empty clusters
z<-z[,-J[!K]]
programclust<-map(z)
}
conv_outer<-1
}
}
# if running for initialization, need to stop after 10 iterations
if(it_outer==10 && all(is.na(initialization) !=TRUE)){
if(all(initialization == "init")){
programclust<-vector()
programclust<-map(z)
conv_outer<-1
}
}
if(conv_outer!=1){ # only update until convergence, not after
z<-zvalue_calculation(theta_Stan=theta_Stan,y=y,G=G,mu_g=mu_g,Sig_g=Sig_g,PI=PI, normalizefactors=normalizefac)
it_outer<-it_outer+1 # updating outer loop iteration
numb_iterations = numb_iterations+10
}
} # end of outer loop
results <- list(finalmu=mu_all_outer[[it_outer]]+ matrix(rep(normalizefac,nrow(mu_all_outer[[it_outer]])),byrow=TRUE,ncol=ncol(mu_all_outer[[it_outer]])),
finalsigma=sigma_all_outer[[it_outer]],
allmu = lapply(mu_all_outer, function(x) (x+matrix(rep(normalizefac,nrow(mu_all_outer[[it_outer]])),byrow=TRUE,ncol=ncol(mu_all_outer[[it_outer]])))),
allsigma = sigma_all_outer,
clusterlabels = programclust,
iterations = it_outer,
proportion = PI,
loglikelihood = logL,
probaPost = z,
stanresults = fit)
class(results) <- "MPLNcluster"
return(results)
} # ending the function
calling_clustering = function(y, Gmin, Gmax, n_chain, numb_iterations=NA, init_method=NA, init_iterations=NA, norm_factors, mod){
ptm_inner = proc.time()
for (gmodel in 1:(Gmax-Gmin+1)){
if(length(1:(Gmax-Gmin+1)) == Gmax){
clustersize = gmodel
}else if(length(1:(Gmax-Gmin+1)) < Gmax){
clustersize = seq(Gmin, Gmax, 1)[gmodel]
}
if(init_iterations!=0){
#cat("\nRunning initialization for G =", clustersize)
initializeruns=initializationrun(gmodel=clustersize, y=y, init_method=init_method, init_iterations=init_iterations, n_chain=n_chain, numb_iterations=numb_iterations, initialization=NA, normalizefactors=norm_factors, mod=mod)
#cat("\nInitialization done for G =", clustersize)
#cat("\nRunning clustering for G =", clustersize)
allruns=cluster_mpln(y=y,z=NA,G=clustersize,n_chain=n_chain,numb_iterations=numb_iterations, initialization=initializeruns,normalizefac=norm_factors, mod=mod)
#cat("\nClustering done for G =", clustersize)
}else if(init_iterations == 0){
#cat("\nNo initialization done for G =", clustersize)
#cat("\nRunning clustering for G =", clustersize)
allruns=cluster_mpln(y=y, z=unmap(kmeans(log(y+1/3),clustersize)$cluster), G=clustersize, n_chain=n_chain, numb_iterations=numb_iterations, initialization=NA, normalizefac=norm_factors, mod=mod)
#cat("\nClustering done for G =", clustersize)
}
}
final_inner<-proc.time()-ptm_inner
RESULTS <- list(  gmin = Gmin,
gmax = Gmax,
initalization_method = init_method,
allresults = allruns,
totaltime = final_inner)
class(RESULTS) <- "MPLN"
return(RESULTS)
}
main_mpln<-function(i, y, membership, Gmin, Gmax, n_chain, numb_iterations=NA, init_method=NA, init_iterations=NA, normalize=NA){
ptm<-proc.time()
if (typeof(y) != "double" & typeof(y) != "integer"){
stop("Dataset type needs to be integer");}
if (Gmax<Gmin){
stop("Gmax cannot be less than Gmin");}
if(is.na(numb_iterations)) numb_iterations <- 1000
#if(is.na(n_chain) || n_chain<3) {
#  n_chain <- 3
#  print("Recommended number of chains is minimum 3. n_chain' set to 3")}
if(numb_iterations<40){
stop("RStan numb_iterations argument should be greater than 40");}
if((is.na(init_iterations) != TRUE && init_iterations == !0) && is.na(init_method) == TRUE){
stop("Number of initialization iterations specified, but no initialization method selected");}
d<-ncol(y)
n<-nrow(y)
if(all(is.na(membership)!=TRUE) && length(membership)!=n){
stop("Length of membership character vector and sample size of dataset should match");}
if(all(is.na(membership)!=TRUE) && all((diff(sort(unique(membership)))==1)!=TRUE) ){
stop("Cluster memberships in the membership vector are missing a cluster, e.g. 1,3,4,5,6 is missing cluster 2");}
if(length(which(apply(y, 1, function(x) all(x==0))==TRUE))!=0){
cat("\nDataset row(s)", c(which(apply(y, 1, function(x) all(x==0))==TRUE)), "will be removed as this/these contain(s) all zeros")
if(all(is.na(membership)==FALSE)){membership<-membership[-c(which(apply(y, 1, function(x) all(x==0))==TRUE))]}
y<-y[-c(which(apply(y, 1, function(x) all(x==0))==TRUE)),]
n<-nrow(y)
}
if(all(is.na(membership)==TRUE)){
membership<-"Not provided"}
if (Gmax > n){
stop("Gmax cannot be larger than n");}
if(is.na(normalize) == FALSE) {
if (!require(edgeR)) install.packages('edgeR') # loading needed package
library(edgeR)
norm_factors<-log(as.vector(calcNormFactors(as.matrix(y), method = "TMM")))
} else {norm_factors<-rep(0,d)}
#cat("\nNormalize factors in main_mpln are: ",norm_factors)
MPLN_parallel = function(g){
## ** Never use set.seed(), use clusterSetRNGStream() instead,
# to set the cluster seed if you want reproducible results
#clusterSetRNGStream(cl=cl, iseed=g)
test = calling_clustering(y=y, Gmin=g, Gmax=g, n_chain=n_chain, numb_iterations=numb_iterations, init_method=init_method, init_iterations=init_iterations, norm_factors=norm_factors, mod=mod)
return(test)
}
#print("Done MPLN_parallel")
# empty list to save output
parallel.Wei_2 = list()
cat("\nRunning parallel code now.")
parallel.Wei_2 = clusterMap(cl=cl,fun=MPLN_parallel, g=Gmin:Gmax)
cat("\nDone parallel code.")
BIC<-ICL<-AIC<-AIC3<-Djump<-DDSE<-k<-ll<-vector()
for(g in 1:(Gmax-Gmin+1)) {
ll[g]<-unlist(tail(parallel.Wei_2[[g]]$allresults$loglikelihood, n=1)) # save the final log-likelihood
k[g]<-calculate_parameters(g,y)
if (g==max(1:(Gmax-Gmin+1))){ # starting model selection
bic<-BIC_function(ll=ll,k=k, n=n, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax)
icl<-ICL_function(bIc=bic, gmin=Gmin, gmax=Gmax, run=parallel.Wei_2)
aic<-AIC_function(ll=ll,k=k, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax )
aic3<-AIC3_function(ll=ll,k=k, run=parallel.Wei_2, gmin=Gmin, gmax=Gmax)
}
}
# for Djump and DDSE
if((Gmax-Gmin+1) > 10 ) {
if (!require(capushe)) install.packages('capushe') # loading needed package
library(capushe)
# adapted based on HTSCluster package 2.0.8 (25 Oct 2016)
PMM<-allruns
runs <- Gmin:Gmax
Gmax <- Gmax
logLike.final <- suppressWarnings(do.call("cbind", lapply(PMM, function(x) x$loglikelihood))) #gives log-likelihood for each cluster at each run
logLike.val <- apply(logLike.final,1,max)
message("Note: diagnostic plots for results corresponding to model selection via slope heuristics (Djump and DDSE) should be examined to ensure that sufficiently complex models have been considered.")
Kchoice <- Gmin:Gmax
k <- k # number of parameters
mat <- cbind(Kchoice, k/n, k/n, -logLike.val)
ResCapushe <- capushe(mat, n)
DDSEmodel<- ResCapushe@DDSE@model
Djumpmodel<- ResCapushe@Djump@model
final<-proc.time()-ptm
RESULTS <- list(dataset= y,
dimensionality = d,
normalization_factors=norm_factors,
gmin = Gmin,
gmax = Gmax,
initalization_method = init_method,
allresults = parallel.Wei_2,
loglikelihood = ll,
numbofparameters = k,
truelabels = membership,
ICL.all = icl,
BIC.all = bic,
AIC.all = aic,
AIC3.all = aic3,
SlopeHeuristics = ResCapushe,
Djumpmodelselected = ResCapushe@Djump@model,
DDSEmodelselected = ResCapushe@DDSE@model,
totaltime = final)
} else {# end of Djump and DDSE
final<-proc.time()-ptm
RESULTS <- list(dataset= y,
dimensionality = d,
normalization_factors=norm_factors,
gmin = Gmin,
gmax = Gmax,
initalization_method = init_method,
allresults = parallel.Wei_2,
loglikelihood = ll,
numbofparameters = k,
truelabels = membership,
ICL.all = icl,
BIC.all = bic,
AIC.all = aic,
AIC3.all = aic3,
SlopeHeuristics = "Not used",
Djumpmodelselected = "Not used",
DDSEmodelselected = "Not used",
totaltime = final)
}
class(RESULTS) <- "MPLN"
return(RESULTS)
}
################################################
#### Running data ####
# Making RStan model #
mod = stan_model("MPLN.stan")
# running code in parallel
if (!require(parallel)) install.packages('parallel') # loading needed package
# Calculate the number of cores
no_cores = detectCores()-1
# Initiate cluster
cl = makeCluster(no_cores)
print("Doing clusterExport")
clusterExport(cl,c("i", "mod", "NBinom_datasets_2clusters","zvalue_calculation", "calc_likelihood", "stanrun", "initializationrun", "BIC_function","ICL_function","AIC_function","AIC3_function", "calculate_parameters", "cluster_mpln", "calling_clustering"))
print("Doing clusterEvalQ")
#other packages need to be downloaded using clusterEvalQ
clusterEvalQ(cl, library(rstan))
clusterEvalQ(cl, library(Rcpp))
clusterEvalQ(cl, library(mclust))
clusterEvalQ(cl, library(mvtnorm))
clusterEvalQ(cl, library(edgeR))
clusterEvalQ(cl, library(capushe))
clusterEvalQ(cl, library(clusterGeneration))
clusterEvalQ(cl, library(coda))
NegBinom_sim_2clusters<-list() # list for saving data results
for (i in 1:numbdatasets){
set.seed(i)
cat("\n Running dataset: ", i)
NegBinom_sim_2clusters[[i]]<-main_mpln(y=NBinom_datasets_2clusters[[i]]$dataset, Gmin=1, Gmax=2, n_chain=3, numb_iterations=300, membership=NA, init_method="kmeans", init_iterations=3, normalize="TMM")
}
source("PackageCheck.R")
LoadCheckPkg(pckgs=c("mvtnorm","mclust","coda","capushe"))
# loading needed packages
LoadCheckPkg(pckgs=c("mvtnorm","mclust","coda","capushe","edgeR","clusterGeneration","pheatmap",
"RColorBrewer","gplots","rstan","Rcpp","parallel"))
source("MPLNDataGenerator.R")
source("AIC3Function.R")
source("AICFunction.R")
source("BICFunction.R")
source("CalcLikelihood.R")
source("CalculateParameters.R")
source("CallingClustering.R")
source("ClusterMPLN.R")
source("ICLFunction.R")
source("InitializationRun.R")
source("MPLNClustering.R")
source("MPLNDataGenerator.R")
source("PackageCheck.R")
source("StanRun.R")
source("ZValueCalculation")
setwd("/Volumes/GoogleDrive/My Drive/UGuelph/Analysis_Anjali'sLaptop/All algorithms (Monte Carlo EM)/mixtures_of_MPLN/Git/GitHub/R")
source("ZValueCalculation")
